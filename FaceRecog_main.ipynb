{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YAP5MAAZBVo2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "2D_Ax8usBhYK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv2\n",
        "from keras.models import load_model"
      ],
      "metadata": {
        "id": "Rv7K2z6cBo75"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPool2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "kyDOWgWYBysA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_OaFVUwtEbo_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Convolution2D(32, kernel_size=(5, 5), strides=(1, 1), input_shape=(64,64,3), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Convolution2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(6, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "BeH1DJgyDKzn"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "8HSEOIwoD6Dg"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #for i in os.listdir('/content/Datset'):\n",
        "#  os.mkdir(i+'/Train')\n",
        "#   os.mkdir(i+'/Test')\n",
        "#   for j in range(0:int(len(os.listdir('/content/Datset/'+ i)))*0.7):\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VegJnI_Jkhk",
        "outputId": "394664c2-2810-4269-a65b-54385047d98a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prince\n",
            "puneet\n",
            "nilu\n",
            "varun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "GoRmsQrLUAOK"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rotation_range=180,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        brightness_range=[0.4,0.6],\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.3)"
      ],
      "metadata": {
        "id": "6y5b_HChUHcj"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = train_datagen.flow_from_directory(\n",
        "        '/content/Dataset/train',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        subset='training',\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gibKAWn-VMj5",
        "outputId": "e9770c2a-5d2d-4da2-e642-83b886532890"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 492 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_set=train_datagen.flow_from_directory(\n",
        "        '/content/Dataset/train',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        subset='validation',\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNI_qU2zVi8K",
        "outputId": "01957a67-5e4d-4d55-de8b-0704065dfe6d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 208 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "StartTime=time.time()\n",
        " \n",
        "model.fit_generator(\n",
        "                    training_set,\n",
        "                    epochs=10,\n",
        "                    validation_data=validation_set,\n",
        "                    validation_steps=10)\n",
        " \n",
        "EndTime=time.time()\n",
        "print(\"otal Time Taken: \", round((EndTime-StartTime)/60), 'Minutes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRPh-Jb3EEfd",
        "outputId": "edaa5026-9c92-4dc1-f8a7-5954c17c05ee"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-6cb8fb5032d7>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - ETA: 0s - loss: 1.2022 - accuracy: 0.4919"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16/16 [==============================] - 7s 413ms/step - loss: 1.2022 - accuracy: 0.4919 - val_loss: 1.1757 - val_accuracy: 0.4519\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 1.1206 - accuracy: 0.5264\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 7s 435ms/step - loss: 0.9750 - accuracy: 0.5935\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 7s 434ms/step - loss: 0.9005 - accuracy: 0.6301\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 6s 346ms/step - loss: 0.9250 - accuracy: 0.6098\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 6s 350ms/step - loss: 0.7516 - accuracy: 0.6646\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 6s 345ms/step - loss: 0.6329 - accuracy: 0.7154\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 0.9337 - accuracy: 0.6179\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 7s 435ms/step - loss: 0.7258 - accuracy: 0.6850\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 0.6394 - accuracy: 0.7358\n",
            "otal Time Taken:  2 Minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes=training_set.class_indices"
      ],
      "metadata": {
        "id": "d5Ax-bStcCPL"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes=list(classes.keys())"
      ],
      "metadata": {
        "id": "RA5NGMOYcy_h"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getclasstitle(classid):\n",
        "    return classes[classid] \n",
        "\n"
      ],
      "metadata": {
        "id": "cB7NMZlhHxXY"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "facedetect=cv2.CascadeClassifier('/content/haarcascade_frontalface_default.xml')\n",
        "cap=cv2.VideoCapture(0)\n",
        "cap.set(3,640)\n",
        "cap.set(4,480)\n",
        "font=cv2.FONT_HERSHEY_COMPLEX"
      ],
      "metadata": {
        "id": "tLaEMQZDZOxk"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "Joxeus4we1qm"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  success, imgOriginal=cap.read()\n",
        "  faces=facedetect.detectMultiScale(imgOriginal,1.3,5)\n",
        "  for x,y,w,h in faces:\n",
        "    crop_img=imgOriginal[y:y+h,x:x+h]\n",
        "    img=cv2.resize(crop_img,(224,224))\n",
        "    img=img.reshape(1,224,224,3)\n",
        "    prediction=model.predict(img)\n",
        "    classIndex=model.predict_classes(img)\n",
        "    probabilityValue=np.amax(prediction)\n",
        "\n",
        "    cv2.rectangle(imgOriginal,(x,y),(x+w,y+h),(0,255,0),2)\n",
        "    cv2.rectangle(imgOriginal,(x,y-40),(x+w,y),(0,255,0),-2)\n",
        "    cv2.putText(imgOriginal, str(getclasstitle(classIndex)),(x,y-10),font,0.75,(255,255,255))\n",
        "\n",
        "    cv2.putText(imgOriginal,str(round(probabilityValue*100,2))+\"%\",(180,75),font,0.75,(255,0,0))\n",
        "\n",
        "  cv2_imshow(imgOriginal)\n",
        "  k=cv2.waitKey(1)\n",
        "  if(k==ord('w')):\n",
        "    break\n",
        "\n",
        "      \n",
        "    \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "REUdSYOkZS7_",
        "outputId": "485cdcdf-ee7e-4219-909d-aea884e57c02"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-fd5ecdde4f99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;31m#   cv2.putText(imgOriginal,str(round(probabilityValue*100,2))+\"%\",(180,75),font,0.75,(255,0,0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgOriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/patches/__init__.py\u001b[0m in \u001b[0;36mcv2_imshow\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \"\"\"\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0;31m# cv2 stores colors as BGR; convert to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'clip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "homcxS-Vbayv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}